# -*- coding: utf-8 -*-
"""Jude neural network assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YBJau9b8bI6FZbj0Bq_DcuiT1amUaL5X
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

predictive_main = pd.read_csv('predictive_main.csv')

data= predictive_main.drop(["ProductID","Type"], axis=1)

data.head()

data.tail()

data.describe()

data.info()

data.shape

data['TWF'].value_counts()

sns.countplot(data['Machinefailure'])

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn

from sklearn.model_selection import train_test_split 

X = data.drop('Machinefailure',axis=1)
#y = data['Machinefailure'] -1
y =data['Machinefailure'] 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,stratify=y, random_state=99)

from imblearn.over_sampling import RandomOverSampler

resampler = RandomOverSampler(random_state = 0)
X_train_oversampled, y_train_oversampled = resampler.fit_resample(X_train, y_train)

sns.countplot(x=y_train_oversampled)

from imblearn.under_sampling import RandomUnderSampler

resampler2 = RandomUnderSampler(random_state = 0)
X_train_undersampled, y_train_undersampled = resampler2.fit_resample(X_train, y_train)

sns.countplot(x=y_train_undersampled)

from imblearn.over_sampling import SMOTE
resampler = SMOTE(random_state = 0)
X_train_smote, y_train_smote = resampler.fit_resample(X_train, y_train)

sns.countplot(x = y_train_smote)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(8,activation='relu',input_shape=(11,)))
model.add(tf.keras.layers.Dense(2,activation='softmax'))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics='accuracy')

model.summary()

class_weights = {0:1, 1:6, 2:7}

history = model.fit(X_train, y_train, \
                    batch_size = 8, epochs= 50, \
                    verbose=2, class_weight=class_weights, \
                    validation_split=0.2)

accuracy = history.history['accuracy']
validation_accuracy = history.history['val_accuracy']

plt.plot(accuracy, label='Training Set Accuracy')
plt.plot(validation_accuracy, label='Validation Set Accuracy')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy Across Epochs')
plt.legend()

loss = history.history['loss']
validation_loss = history.history['val_loss']


plt.plot(loss, label='Training Set Loss')
plt.plot(validation_loss, label='Validation Set Loss')
plt.ylabel('Loss')
plt.title('Training and Validation Accuracy Across Epochs')
plt.legend()

y_pred = model.predict(X_test)
y_pred = y_pred.argmax(axis=1)

data["Toolwear"].value_counts()

from sklearn.metrics import confusion_matrix, classification_report

confusion_matrixs = confusion_matrix(y_test,y_test)

                                    
ax = sns.heatmap(confusion_matrixs, cmap='flare',annot=True, fmt='d')


plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)

plt.show()

print(classification_report(y_test,y_pred))

